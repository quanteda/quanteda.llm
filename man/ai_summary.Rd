% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ai_summary.R
\name{ai_summary}
\alias{ai_summary}
\title{Summarize documents in a corpus or character vector}
\usage{
ai_summary(.data, chat_fn, ..., verbose = TRUE)
}
\arguments{
\item{.data}{a character or [quanteda::corpus] object containing the
documents to be summarized}

\item{chat_fn}{function; a chat function from \pkg{ellmer}}

\item{...}{additional arguments passed to `chat_fn`}

\item{verbose}{logical; output a progress indicator if `TRUE`}

\item{model}{a llm model object}

\item{topics}{character; a vector of topic names for which salience scores}
}
\value{
character; the response from the LLM with a length equal to the
  number of input documents, with the elements named with the input element
  names
}
\description{
This function is a wrapper around `ai_text` to summarize documents using a chat function.
}
\examples{
\dontrun{
library(quanteda)
summaries <- ai_summary(data_corpus_inaugural, chat_fn = chat_openai, model = "gpt-4o",
                api_args = list(temperature = 0, seed = 42))
}
}
