% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ai_relevance.R
\name{ai_relevance}
\alias{ai_relevance}
\title{Classifies documents in a corpus according to a content analysis scheme}
\usage{
ai_relevance(.data, chat_fn, ..., topics, verbose = TRUE)
}
\arguments{
\item{.data}{a character or [quanteda::corpus] object containing the
documents to be summarized}

\item{chat_fn}{function; a chat function from \pkg{ellmer}}

\item{...}{additional arguments passed to `chat_fn`}

\item{topics}{the topics of the defined content analysis scheme - be as specific as possible}

\item{verbose}{logical; output a progress indicator if `TRUE`}

\item{model}{a llm model object}
}
\value{
character; the response from the LLM with a length equal to the
  number of input documents, with the elements named with the input element
  names
}
\description{
Use the llm model to analyse a set of documents. The text-based response is
added as an additional column to the input data.
}
\examples{
\dontrun{
library(quanteda)
topics = c("Politics", "Sports", "Technology", "Entertainment", "Business", "Other")
topic_relevance1 <- ai_relevance(data_corpus_inaugural[1:2], chat_fn = chat_ollama, model = "llama3.2", topics = topics)
topic_relevance2 <- ai_relevance(data_char_ukimmig2010, chat_fn = chat_openai,
               api_args = list(temperature = 0, seed = 42), topics = topics)
}
}
