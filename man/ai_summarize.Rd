% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/ai_summarize.R
\name{ai_summarize}
\alias{ai_summarize}
\title{Summarize documents in a corpus}
\usage{
ai_summarize(.data, chat_fn, ..., summary_length = 200L, verbose = TRUE)
}
\arguments{
\item{.data}{a character or [quanteda::corpus] object containing the
documents to be summarized}

\item{chat_fn}{function; a chat function from \pkg{ellmer}}

\item{...}{additional arguments passed to `chat_fn`}

\item{summary_length}{integer; the length in words to instruct the chat function
to return in the response}

\item{verbose}{logical; output a progress indicator if `TRUE`}

\item{model}{a llm model object}
}
\value{
character; the response from the LLM with a length equal to the
  number of input documents, with the elements named with the input element
  names
}
\description{
Use the llm model to summarize a set of documents.
The response is added as an additional docvar to the input data
}
\examples{
\dontrun{
library(quanteda)
summ1 <- ai_summarize(data_char_ukimmig2010, chat_fn = chat_ollama, model = "llama3.2")
summ2 <- ai_summarize(data_corpus_inaugural[1:2], chat_fn = chat_openai,
                api_args = list(temperature = 0, seed = 42))
}
}
