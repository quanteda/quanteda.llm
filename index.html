<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en-GB">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>LLM support for quanteda corpus objects • quanteda.llm</title>
<script src="deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="deps/headroom-0.11.0/headroom.min.js"></script><script src="deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="deps/search-1.0.0/fuse.min.js"></script><script src="deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="pkgdown.js"></script><meta property="og:title" content="LLM support for quanteda corpus objects">
<meta name="description" content="Provides support for linking quanteda corpus objects to structured, flexible analysis by LLMs.">
<meta property="og:description" content="Provides support for linking quanteda corpus objects to structured, flexible analysis by LLMs.">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="index.html">quanteda.llm</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.5</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-quick-start" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Quick Start</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-quick-start">
<li><a class="dropdown-item" href="articles/getting-started.html">Quick Start Guide</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-examples" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Examples</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-examples">
<li><a class="dropdown-item" href="articles/pkgdown/examples/summarizing.html">Summarizing texts</a></li>
    <li><a class="dropdown-item" href="articles/pkgdown/examples/salience.html">Salience rating of topics</a></li>
    <li><a class="dropdown-item" href="articles/pkgdown/examples/scoring.html">Scaling texts</a></li>
    <li><a class="dropdown-item" href="articles/pkgdown/examples/structuring.html">Structuring LLM responses for text analysis</a></li>
    <li><a class="dropdown-item" href="articles/pkgdown/examples/validating.html">Validating LLM responses</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/quanteda/quanteda.llm" aria-label="View on GitHub"><span class="fa fab fa-github"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-home">
<div class="row">
  <main id="main" class="col-md-9"><div class="section level1">
<div class="page-header"><h1 id="quantedallm">quanteda.llm<a class="anchor" aria-label="anchor" href="#quantedallm"></a>
</h1></div>
<!-- badges: start -->

<p>The <strong>quanteda.llm</strong> package makes it easy to use LLMs with <a href="https://quanteda.io/" class="external-link">quanteda</a> corpora (or character vectors and data frames), to enable classification, summarisation, scoring, and analysis of documents and text. <strong>quanteda</strong> provides a host of convenient functions for managing, manipulating, and describing corpora as well as linking their document variables and metadata to these documents. <strong>quanteda.llm</strong> makes it convenient to link these to LLMs for analysing or classifying these texts, creating new variables from what is created by the LLMs.</p>
</div>
<div class="section level1">
<h1 id="included-functions">Included functions<a class="anchor" aria-label="anchor" href="#included-functions"></a>
</h1>
<p>The package includes the following functions:</p>
<ul>
<li>
<code><a href="reference/ai_text.html">ai_text()</a></code>:
<ul>
<li>A generic function that can be used with any LLM supported by <code>ellmer</code>.</li>
<li>Generates structured responses or classifications based on pre-defined instructions for texts in a <code>quanteda corpus</code>.</li>
<li>Users can flexibly define prompts and structure of responses via <code>type_object()</code> from the <a href="https://ellmer.tidyverse.org/articles/structured-data.html" class="external-link"><code>ellmer</code> package</a>.</li>
<li>Users can add a dataset with examples to improve LLM performance (few-shot prompting)</li>
<li>Supports resuming interrupted processes in a <code>result_env</code> environment.</li>
</ul>
</li>
<li>
<code><a href="reference/ai_validate.html">ai_validate()</a></code>:
<ul>
<li>Starts an interactive app to manually validate the LLM-generated outputs.</li>
<li>Allows users to review and validate the LLM-generated outputs and justifications, marking them as valid or invalid.</li>
<li>Supports resuming the validation process in case of interruptions in a <code>result_env</code> environment.</li>
</ul>
</li>
<li>
<code><a href="reference/ai_summary.html">ai_summary()</a></code>:
<ul>
<li>A wrapper around <code><a href="reference/ai_text.html">ai_text()</a></code> for summarizing documents in a corpus.</li>
<li>Uses a pre-defined <code>type_object()</code> to structure the summary output.</li>
</ul>
</li>
<li>
<code><a href="reference/ai_salience.html">ai_salience()</a></code>:
<ul>
<li>A wrapper around <code><a href="reference/ai_text.html">ai_text()</a></code> for computing salience scores for topics in a corpus.</li>
<li>Uses a pre-defined <code>type_object()</code> to structure the salience classification output.</li>
</ul>
</li>
<li>
<code><a href="reference/ai_score.html">ai_score()</a></code>:
<ul>
<li>A wrapper around <code><a href="reference/ai_text.html">ai_text()</a></code> for scoring documents based on a scale defined by a prompt.</li>
<li>Uses a pre-defined <code>type_object()</code> to structure the scoring output.</li>
</ul>
</li>
</ul>
</div>
<div class="section level1">
<h1 id="supported-llms">Supported LLMs<a class="anchor" aria-label="anchor" href="#supported-llms"></a>
</h1>
<p>The package supports all LLMs currently available with the <code>ellmer</code> package, including:</p>
<ul>
<li>Anthropic’s Claude: <code>chat_anthropic()</code>.</li>
<li>AWS Bedrock: <code>chat_aws_bedrock()</code>.</li>
<li>Azure OpenAI: <code>chat_azure_openai()</code>.</li>
<li>Cloudflare: <code>chat_cloudflare()</code>.</li>
<li>Databricks: <code>chat_databricks()</code>.</li>
<li>DeepSeek: <code>chat_deepseek()</code>.</li>
<li>GitHub model marketplace: <code>chat_github()</code>.</li>
<li>Google Gemini/Vertex AI: <code>chat_google_gemini()</code>, <code>chat_google_vertex()</code>.</li>
<li>Groq: <code>chat_groq()</code>.</li>
<li>Hugging Face: <code>chat_huggingface()</code>.</li>
<li>Mistral: <code>chat_mistral()</code>.</li>
<li>Ollama: <code>chat_ollama()</code>.</li>
<li>OpenAI: <code>chat_openai()</code>.</li>
<li>OpenRouter: <code>chat_openrouter()</code>.</li>
<li>perplexity.ai: <code>chat_perplexity()</code>.</li>
<li>Snowflake Cortex: <code>chat_snowflake()</code> and <code>chat_cortex_analyst()</code>.</li>
<li>VLLM: <code>chat_vllm()</code>.</li>
</ul>
<p>For authentication and usage of each of these LLMs, please refer to the respective <code>ellmer</code> documentation <a href="https://ellmer.tidyverse.org/reference/index.html" class="external-link">here</a>. <strong>For example,</strong> to use the <code>chat_openai</code> models, you would need to sign up for an API key from <a href="https://platform.openai.com/playground/prompts" class="external-link">OpenAI</a> which you can save in your <code>.Renviron</code> file as <code>OPENAI_API_KEY</code>. To use the <code>chat_ollama</code> models, first download and install <a href="https://ollama.com/" class="external-link">Ollama</a>. Then install some models either from the command line (e.g. with ollama pull llama3.1) or within R using the <code>rollama</code> package. The Ollama app must be running for the models to be used.</p>
<div class="section level2">
<h2 id="installation">Installation<a class="anchor" aria-label="anchor" href="#installation"></a>
</h2>
<p>You can install the development version of <strong>quanteda.llm</strong> from <a href="https://github.com/quanteda/quanteda.llm" class="external-link uri">https://github.com/quanteda/quanteda.llm</a> with:</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># install.packages("pak")</span></span>
<span><span class="fu">pak</span><span class="fu">::</span><span class="fu"><a href="https://pak.r-lib.org/reference/pak.html" class="external-link">pak</a></span><span class="op">(</span><span class="st">"quanteda/quanteda.llm"</span><span class="op">)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="example-use">Example use<a class="anchor" aria-label="anchor" href="#example-use"></a>
</h2>
<p>To learn more about how to use the package, please refer to the following examples:</p>
<ul>
<li><a href="https://quanteda.github.io/quanteda.llm/articles/pkgdown/examples/summarizing.html">Summarizing texts with LLMs</a></li>
<li><a href="https://quanteda.github.io/quanteda.llm/articles/pkgdown/examples/salience.html">Salience ratings of topics in texts with LLMs</a></li>
<li><a href="https://quanteda.github.io/quanteda.llm/articles/pkgdown/examples/scoring.html">Scoring texts with LLMs</a></li>
<li><a href="https://quanteda.github.io/quanteda.llm/articles/pkgdown/examples/structuring.html">Structuring LLM responses for text analysis</a></li>
<li><a href="https://quanteda.github.io/quanteda.llm/articles/pkgdown/examples/validating.html">Validating LLM responses</a></li>
</ul>
</div>
</div>

  </main><aside class="col-md-3"><div class="links">
<h2 data-toc-skip>Links</h2>
<ul class="list-unstyled">
<li><a href="https://github.com/quanteda/quanteda.llm/" class="external-link">Browse source code</a></li>
<li><a href="https://github.com/quanteda/quanteda.llm/issues" class="external-link">Report a bug</a></li>
</ul>
</div>

<div class="license">
<h2 data-toc-skip>License</h2>
<ul class="list-unstyled">
<li><a href="https://www.r-project.org/Licenses/GPL-3" class="external-link">GPL-3</a></li>
</ul>
</div>


<div class="citation">
<h2 data-toc-skip>Citation</h2>
<ul class="list-unstyled">
<li><a href="authors.html#citation">Citing quanteda.llm</a></li>
</ul>
</div>

<div class="developers">
<h2 data-toc-skip>Developers</h2>
<ul class="list-unstyled">
<li>Seraphine F. Maerz <br><small class="roles"> Author, maintainer </small> <a href="https://orcid.org/0000-0002-7173-9617" target="orcid.widget" aria-label="ORCID" class="external-link"><span class="fab fa-orcid orcid" aria-hidden="true"></span></a>  </li>
<li>Kenneth Benoit <br><small class="roles"> Author </small> <a href="https://orcid.org/0000-0002-0797-564X" target="orcid.widget" aria-label="ORCID" class="external-link"><span class="fab fa-orcid orcid" aria-hidden="true"></span></a>  </li>
</ul>
</div>

<div class="dev-status">
<h2 data-toc-skip>Dev status</h2>
<ul class="list-unstyled">
<li><a href="https://lifecycle.r-lib.org/articles/stages.html#experimental" class="external-link"><img src="https://img.shields.io/badge/lifecycle-experimental-orange.svg" alt="Lifecycle: experimental"></a></li>
<li><a href="https://CRAN.R-project.org/package=quanteda.llm" class="external-link"><img src="https://www.r-pkg.org/badges/version/quanteda.llm" alt="CRAN status"></a></li>
<li><a href="https://github.com/quanteda/quanteda.llm/actions/workflows/R-CMD-check.yaml" class="external-link"><img src="https://github.com/quanteda/quanteda.llm/actions/workflows/R-CMD-check.yaml/badge.svg" alt="R-CMD-check"></a></li>
<li><a href="https://app.codecov.io/gh/quanteda/quanteda.llm" class="external-link"><img src="https://codecov.io/gh/quanteda/quanteda.llm/graph/badge.svg" alt="Codecov test coverage"></a></li>
<li><a href="https://quanteda.github.io/quanteda.llm/"><img src="https://img.shields.io/badge/pkgdown-site-blue" alt="pkgdown"></a></li>
</ul>
</div>

  </aside>
</div>


    <footer><div class="pkgdown-footer-left">
  <p>Developed by Seraphine F. Maerz, Kenneth Benoit.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
