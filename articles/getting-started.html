<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en-GB">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Getting started with quanteda.llm • quanteda.llm</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Getting started with quanteda.llm">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">quanteda.llm</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.4.2</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-quick-start" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Quick Start</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-quick-start">
<li><a class="dropdown-item" href="../articles/getting-started.html">Quick Start Guide</a></li>
  </ul>
</li>
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-examples" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Examples</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-examples">
<li><a class="dropdown-item" href="../articles/pkgdown/examples/summarizing.html">Summarizing texts</a></li>
    <li><a class="dropdown-item" href="../articles/pkgdown/examples/salience.html">Salience rating of topics</a></li>
    <li><a class="dropdown-item" href="../articles/pkgdown/examples/scoring.html">Scaling texts</a></li>
    <li><a class="dropdown-item" href="../articles/pkgdown/examples/structuring.html">Structuring LLM responses for text analysis</a></li>
    <li><a class="dropdown-item" href="../articles/pkgdown/examples/validating.html">Validating LLM responses</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/quanteda/quanteda.llm"><span class="fa fab fa-github"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Getting started with quanteda.llm</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/quanteda/quanteda.llm/blob/main/vignettes/getting-started.Rmd" class="external-link"><code>vignettes/getting-started.Rmd</code></a></small>
      <div class="d-none name"><code>getting-started.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="introduction">Introduction<a class="anchor" aria-label="anchor" href="#introduction"></a>
</h2>
<p>This vignette provides a brief introduction to the
<code>quanteda.llm</code> package, which is designed to facilitate the
use of large language models (LLMs) in text analysis workflows. The
package integrates with the <a href="https://quanteda.io/" class="external-link"><code>quanteda</code> framework</a>,
allowing users to leverage LLMs for various text processing tasks. The
package relies on the <code>ellmer</code> package for LLM interactions,
providing a seamless interface for users to work with different LLM
providers. For more information on the <code>ellmer</code> package and
supported LLM interactions, please refer to its documentation <a href="https://ellmer.tidyverse.org/index.html" class="external-link">here</a>.</p>
</div>
<div class="section level2">
<h2 id="basic-usage">Basic usage<a class="anchor" aria-label="anchor" href="#basic-usage"></a>
</h2>
<p>To get started with <code>quanteda.llm</code>, you first need to
install the package from GitHub. Then, you can load the package and
begin using its functions.</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/quanteda/quanteda.llm" class="external-link">quanteda.llm</a></span><span class="op">)</span></span>
<span><span class="co">#&gt; Loading required package: ellmer</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="analyzing-texts">Analyzing texts<a class="anchor" aria-label="anchor" href="#analyzing-texts"></a>
</h2>
<p>The <code>quanteda.llm</code> package provides functions to analyze
large amounts of texts using LLMs. This is similar to manual
annotations, but it automates the process using LLMs. The package
includes functions for summarization, salience rating, scaling, and
other text analysis tasks.</p>
</div>
<div class="section level2">
<h2 id="structuring-llm-responses">Structuring LLM responses<a class="anchor" aria-label="anchor" href="#structuring-llm-responses"></a>
</h2>
<p>The package allows you to structure the responses from LLMs in a way
that is compatible with <code>quanteda</code>’s corpus principles and
useful for common text analysis tasks. This means you can easily
integrate LLM-generated data into your text analysis workflows. For
example, you can ask an LLM to summarize all documents in a corpus
(<code><a href="../reference/ai_summary.html">ai_summary()</a></code>) and store the summaries as document
variables, or you can classify documents into topics
(<code><a href="../reference/ai_salience.html">ai_salience()</a></code>) or scale them based on predefined criteria
(<code>ai_scale()</code>) and store the results as document
variables.</p>
<p>If you need more flexibility in how the LLM generates its output, you
can use the <code><a href="../reference/ai_text.html">ai_text()</a></code> function to define custom prompts and
response structures. With <code><a href="../reference/ai_text.html">ai_text()</a></code> and the help of the
<code><a href="https://ellmer.tidyverse.org/reference/type_boolean.html" class="external-link">type_object()</a></code> argument from the <code>ellmer</code>
package, you can define how the LLM should format its output, such as
specifying the fields to include in the response or the format of the
response itself. This flexibility enables you to tailor the LLM’s output
to your analysis requirements, making it easier to integrate
LLM-generated data into your text analysis workflows.</p>
</div>
<div class="section level2">
<h2 id="example-uses">Example uses<a class="anchor" aria-label="anchor" href="#example-uses"></a>
</h2>
<p>This vignette provides a brief overview of how to use the
<code>quanteda.llm</code> package for analyzing texts with LLMs. The
following examples demonstrate how to summarize documents, classify
topics, and score documents using LLMs. At the end, we will also show
how to validate LLM responses manually and customize the structure of
LLM responses for more advanced text analysis tasks.</p>
<p>For more detailed examples including <strong>code snippets</strong>,
please refer to the section <a href="">Examples</a>.</p>
<div class="section level3">
<h3 id="summarizing-documents">Summarizing documents<a class="anchor" aria-label="anchor" href="#summarizing-documents"></a>
</h3>
<p>The <code><a href="../reference/ai_summary.html">ai_summary()</a></code> function allows you to summarize
documents using an LLM. It generates a summary for each document in a
character vector and stores it as a new character vector which can be
added as a document variable in a <code>quanteda</code> corpus element.
The function uses a predefined <code>type_object</code> argument from
<code>ellmer</code> to structure the LLM’s response, producing succinct
summaries of each document. Users need to provide a character vector of
documents to summarize and choose the LLM provider they want to use for
summarization.</p>
</div>
<div class="section level3">
<h3 id="salience-rating-of-topics-in-documents">Salience rating of topics in documents<a class="anchor" aria-label="anchor" href="#salience-rating-of-topics-in-documents"></a>
</h3>
<p>The <code><a href="../reference/ai_salience.html">ai_salience()</a></code> function allows you to classify
documents based on their relevance to predefined topics. The function
uses a predefined <code>type_object</code> argument from
<code>ellmer</code> to structure the LLM’s response, producing a list of
topics and their salience scores for each document. This function is
particularly useful for analyzing large corpora where manual
classification would be impractical. Users need to provide a character
vector of documents and a list of topics to classify. The LLM will then
analyze each document and assign a salience score to each topic,
indicating how relevant the document is to that topic.</p>
</div>
<div class="section level3">
<h3 id="scoring-documents-on-a-predefined-scale">Scoring documents on a predefined scale<a class="anchor" aria-label="anchor" href="#scoring-documents-on-a-predefined-scale"></a>
</h3>
<p>The <code><a href="../reference/ai_score.html">ai_score()</a></code> function allows you to score documents
based on a predefined scale. The function uses a predefined
<code>type_object</code> argument from <code>ellmer</code> to structure
the LLM’s response, producing a score for each document based on the
specified scale as well as a short justification for the score. This
function is useful for evaluating documents against specific criteria or
benchmarks. Users need to provide a character vector of documents and a
scale to score against. The LLM will then analyze each document and
assign a score based on the provided scale, along with a brief
explanation of the reasoning behind the score.</p>
</div>
<div class="section level3">
<h3 id="manually-checking-and-validating-llm-responses">Manually checking and validating LLM responses<a class="anchor" aria-label="anchor" href="#manually-checking-and-validating-llm-responses"></a>
</h3>
<p>The <code><a href="../reference/ai_validate.html">ai_validate()</a></code> function allows users to manually
check and validate the responses generated by the LLM with a
user-friendly ShinyApp. Such manual checks are essential for ensuring
the quality and accuracy of the LLM’s output. The function can be used
to review the scores and justifications generated by the LLM, and users
can also highlight and save examples from the original texts that
support the validated text classifications. The saved examples can be
used for further qualitative analyses or to built a labelled dataset for
fine-tuning open-source LLMs to receive improved performance on similar
tasks.</p>
</div>
<div class="section level3">
<h3 id="customizing-the-structure-of-llm-responses">Customizing the structure of LLM responses<a class="anchor" aria-label="anchor" href="#customizing-the-structure-of-llm-responses"></a>
</h3>
<p>The <code>quanteda.llm</code> package allows you to customize the
structure of LLM responses to fit your specific analysis needs. You can
define how the LLM should format its output, such as specifying the
fields to include in the response or the format of the response itself.
This flexibility enables you to tailor the LLM’s output to your analysis
requirements, making it easier to integrate LLM-generated data into your
text analysis workflows.</p>
<p>For such more advanced text analysis tasks, you can use the
<code><a href="../reference/ai_text.html">ai_text()</a></code> function to define custom prompts and response
structures. This function allows you to specify how the LLM should
generate its output, including the format and content of the response.
By using <code><a href="https://ellmer.tidyverse.org/reference/type_boolean.html" class="external-link">type_object()</a></code> from the <code>ellmer</code>
package, you can define the structure of the LLM’s response, making it
easier to integrate LLM-generated data into your text analysis
workflows.</p>
</div>
</div>
<div class="section level2">
<h2 id="conclusion">Conclusion<a class="anchor" aria-label="anchor" href="#conclusion"></a>
</h2>
<p>The <code>quanteda.llm</code> package provides a powerful and
flexible framework for integrating large language models into text
analysis workflows. By leveraging LLMs, users can automate various text
processing tasks, such as summarization, classification, and scoring,
while maintaining compatibility with the <code>quanteda</code>
framework. The package’s ability to structure LLM responses and
customize output formats makes it a valuable tool for researchers and
analysts working with large text corpora.</p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Seraphine F. Maerz, Kenneth Benoit.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.3.</p>
</div>

    </footer>
</div>





  </body>
</html>
